
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{listings}
\usepackage[numbers]{natbib} %IEEE
\usepackage{color}
\usepackage{hyperref}
\usepackage{soul}
\usepackage{float}
\usepackage{pgfplotstable}
\usepackage[font=itshape]{quoting}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{multicol}
%\usepackage[table,xcdraw]{xcolor}

\usepackage{minted}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{codegreen}{rgb}{0,0.6,0}
% Define a custom style
\lstdefinestyle{myStyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle = \bfseries\color{mauve},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    keepspaces=true,                 
    numbers=left,       
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
}
\lstset{style=mystyle}

\title{Data Mining \& Machine Learning \\ \large Project 4 - Classification Based on Probability}
\author{Steinarr Hrafn HÃ¶skuldsson}
\date{September 2022}
\newcommand{\mycomment}[1]{}

\begin{document}
\maketitle
\mycomment{
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{LAB3/Basic1.png}
    \caption{"Switch test" Breadboard set up}
    \label{fig:Switch_test}
\end{figure}

\lstinputlisting[caption=Defining 'ColorMatch' state, label={lst:colormatch}, language=Python, firstline=44, lastline=52]{LAB3/Basic.py}

}
\section*{Section 2.2}
\begin{quoting}
\begin{itemize}
    \item  What is the accuracy of each method?
    \item How are the confusion matrices? Use your own code from assignment 1 and compare the matrices.
    \item How do you interpret the differences? Why is/is not a difference in accuracy?
    
\end{itemize}
\end{quoting}

The accuracy of both method is the same, 98\%. The confusion matrices are also identical:\\
\begin{center}
CM = \begin{bmatrix}
    19 & 0 & 0\\
0 & 19 & 1\\
0 & 0 & 20
    \end{bmatrix}
    \end{center}
\\
And it makes sense that they are identical because our dataset is equally split between classes. When estimating the maximum likelihood we assume that the prior probability of each class is equal. In this particular dataset this is actually true. So incorporating the class prior probability of into our maximum likelihood estimation does not change any of the probability estimates.
\section*{Independent}
A maximum likelihood classification can be seen a special case of a posteriori classification when prior probability of each class is equal. So when the dataset is balanced there is no difference. If the features do a good job of describing and differentiating the data then incorporating the prior probability, assuming an unbalanced dataset, will only do harm to the accuracy. So for a posteriori classification to outperform a maximum likelihood classification the dataset needs to be unbalanced, and the features should not do a good job of describing the targets.
As an example of such a dataset I created a dataset with 1000 simulations of flipping 10 coins to predict the throw of a unfair 4 sided die. Using the same methods as were used in sections 1 and 2 the following confusion matrices and accuracies were found:
\\

\begin{minipage}[0]{0.5\textwidth}
Using maximum likelihood estimation:\\
CM_{MLE} = \begin{bmatrix}
    4 & 6 & 5 & 10\\
    4 & 1 & 9 & 11\\
    20 & 15 & 24 & 44\\
    13 & 22 & 31 & 34
\end{bmatrix}\\
Accuracy = 25\%
 \end{minipage}
\begin{minipage}[0.5\textwidth]{0.5\textwidth}
Using a posteriori classification:\\
CM_{MAP}\begin{bmatrix}
    1 & 1 & 15 & 8\\
    0 & 0 & 16 & 9\\
    6 & 0 & 52 & 45\\
    3 & 4 & 51 & 42
\end{bmatrix}\\
Accuracy = 37.5\%
 \end{minipage}
 
 As can be seen the a posteriori classification doesn't waste guesses on the unlikely sides of the unfair die, making it more likely to guess correctly.
\end{document}

